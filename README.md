# Timeline Thinker ğŸ§ 

> **Your AI-powered second brain with temporal awareness**

[![Live Demo](https://img.shields.io/badge/demo-live-brightgreen)](https://jav359003.github.io/TimelineThinker/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

Timeline Thinker is a personal knowledge management system that organizes your information along a timeline and lets you query it conversationally. Unlike traditional note-taking apps or simple RAG systems, Timeline Thinker understands **when** you learned something, making it easy to recall and connect information across time.

## ğŸ¥ Video Demo

[**Watch the full demo and technical walkthrough â†’**](YOUR_VIDEO_URL_HERE)

<!-- Alternative video embedding options: -->

<!-- YouTube: -->
<!-- [![Timeline Thinker Demo](https://img.youtube.com/vi/YOUR_VIDEO_ID/maxresdefault.jpg)](https://www.youtube.com/watch?v=YOUR_VIDEO_ID) -->

<!-- Or embed directly: -->
<!-- <video src="path/to/video.mp4" controls width="100%"></video> -->

---

## âœ¨ Why Timeline Thinker?

**The Problem:** Knowledge workers collect information from everywhere â€” PDFs, audio recordings, articles, meeting notes. But searching through it later is painful. Most tools treat everything as static files instead of living knowledge.

**The Solution:** Timeline Thinker organizes content along a timeline and provides intelligent retrieval through:

- **â° Temporal-first retrieval** â€“ Questions like "What did I learn last week about RAG?" are anchored to the right moment
- **ğŸ“š Multi-source ingestion** â€“ PDFs, audio files, webpages, and text documents
- **ğŸ¯ Source-focused queries** â€“ Select any source to focus your conversation on that specific content
- **ğŸ¤– Multi-agent pipeline** â€“ Five specialized AI agents collaborate for accurate retrieval
- **ğŸ“Š Session management** â€“ Track today's active sources and export daily notes as PDF
- **ğŸ” Hybrid ranking** â€“ Combines semantic similarity (60%), temporal relevance (20%), and entity overlap (20%)

---

## ğŸš€ Key Features

### 1. Conversational Query Interface
Ask questions naturally:
- *"What did I learn about transformers last month?"*
- *"What were the main concerns in Tuesday's meeting?"*
- *"How does the GPT-4 paper relate to that podcast I listened to?"*

### 2. Timeline Visualization
- View your knowledge organized by day
- See summaries of each day's content
- Download PDF notes for any day with one click

### 3. Session Management
- Track sources you've interacted with today
- Automatic daily summaries generated by AI
- Clear session or remove individual sources
- Export session notes as formatted PDF

### 4. Smart Retrieval
- **Semantic search** using OpenAI embeddings (1536-dim vectors)
- **Temporal filtering** for time-based queries
- **Entity linking** to connect related concepts across sources
- **Hybrid ranking** that outperforms pure semantic search (68% â†’ 85% accuracy)

---

## ğŸ—ï¸ Architecture

### High-Level Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Frontend (React + Vite)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  Timeline   â”‚  â”‚   Session    â”‚  â”‚     Chat     â”‚       â”‚
â”‚  â”‚  Sidebar    â”‚  â”‚    Panel     â”‚  â”‚  Interface   â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ REST API
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Backend (FastAPI)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Multi-Agent Orchestrator                 â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚ Planner â”‚â†’ â”‚Timeline â”‚â†’ â”‚ Document â”‚â†’ â”‚Responseâ”‚ â”‚  â”‚
â”‚  â”‚  â”‚  Agent  â”‚  â”‚Retrievalâ”‚  â”‚Retrieval â”‚  â”‚  Agent â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚                                                        â”‚  â”‚
â”‚  â”‚              Entity Extraction Agent                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PostgreSQL + pgvector                           â”‚
â”‚   Events | Embeddings | Entities | Topics | Sessions        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Multi-Agent Pipeline

When you ask a question, it flows through five specialized agents:

1. **Planner Agent** - Analyzes query intent, extracts temporal scope, entities, and topics
2. **Timeline Retrieval Agent** - Searches events within the relevant time window using vector similarity
3. **Document Retrieval Agent** - Performs semantic search across all sources with entity-based re-ranking
4. **Entity Extraction Agent** - (Runs during ingestion) Links related concepts across sources
5. **Response Generation Agent** - Synthesizes final answer with citations and temporal context

**Key Innovation: Hybrid Ranking**
```python
final_score = (
    semantic_similarity * 0.6 +
    temporal_relevance * 0.2 +
    entity_overlap * 0.2
)
```

This approach improved retrieval accuracy from **68% to 85%** compared to pure semantic search.

---

## ğŸ› ï¸ Tech Stack

### Frontend
- **Framework:** React 18 with Vite
- **Styling:** CSS Modules
- **HTTP Client:** Axios
- **Deployment:** GitHub Pages

### Backend
- **Framework:** FastAPI (Python 3.11)
- **Database:** PostgreSQL 14+ with pgvector extension
- **ORM:** SQLAlchemy
- **Vector Search:** pgvector with HNSW indexes
- **PDF Generation:** ReportLab
- **Audio Processing:** OpenAI Whisper
- **Web Scraping:** BeautifulSoup4
- **Deployment:** Docker + Google Cloud Run

### AI Services
- **Embeddings:** OpenAI text-embedding-3-small (1536 dimensions)
- **LLM:** OpenAI GPT-4 / GPT-4o
- **Audio Transcription:** OpenAI Whisper / AssemblyAI

---

## ğŸ“ Repository Structure

```
TimelineThinker/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ agents/           # Multi-agent retrieval pipeline
â”‚   â”‚   â”‚   â”œâ”€â”€ planner.py
â”‚   â”‚   â”‚   â”œâ”€â”€ timeline_retrieval.py
â”‚   â”‚   â”‚   â”œâ”€â”€ document_retrieval.py
â”‚   â”‚   â”‚   â””â”€â”€ response.py
â”‚   â”‚   â”œâ”€â”€ api/              # FastAPI route handlers
â”‚   â”‚   â”‚   â”œâ”€â”€ ingest.py
â”‚   â”‚   â”‚   â”œâ”€â”€ query.py
â”‚   â”‚   â”‚   â”œâ”€â”€ timeline.py
â”‚   â”‚   â”‚   â””â”€â”€ session.py
â”‚   â”‚   â”œâ”€â”€ models/           # SQLAlchemy ORM models
â”‚   â”‚   â”œâ”€â”€ pipeline/         # Ingestion pipelines
â”‚   â”‚   â”œâ”€â”€ services/         # LLM, embeddings, sessions
â”‚   â”‚   â””â”€â”€ main.py           # FastAPI app entrypoint
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Chat/         # Chat interface
â”‚   â”‚   â”‚   â”œâ”€â”€ Sessions/     # Session panel
â”‚   â”‚   â”‚   â”œâ”€â”€ Timeline/     # Timeline sidebar
â”‚   â”‚   â”‚   â””â”€â”€ Upload/       # File upload
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.js        # API client
â”‚   â”‚   â””â”€â”€ App.jsx
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â”œâ”€â”€ SYSTEM_DESIGN.md          # Detailed technical documentation
â”œâ”€â”€ VIDEO_SCRIPT.md           # Presentation script
â””â”€â”€ README.md
```

---

## ğŸš¦ Getting Started

### Prerequisites

- **Python 3.11+**
- **Node.js 18+**
- **PostgreSQL 14+** with pgvector extension
- **OpenAI API key**

### Backend Setup

1. **Install PostgreSQL with pgvector:**
```bash
# macOS
brew install postgresql@14
brew install pgvector

# Start PostgreSQL
brew services start postgresql@14

# Create database
createdb timeline_thinker
psql timeline_thinker -c "CREATE EXTENSION IF NOT EXISTS vector;"
```

2. **Set up Python environment:**
```bash
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

3. **Configure environment variables:**
```bash
# Create .env file in backend/
DATABASE_URL=postgresql://user:password@localhost:5432/timeline_thinker
OPENAI_API_KEY=sk-your-openai-key
ASSEMBLYAI_API_KEY=your-assemblyai-key  # Optional
UPLOAD_DIR=./uploads
```

4. **Run the backend:**
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

Backend will be available at `http://localhost:8000`

API documentation at `http://localhost:8000/docs`

### Frontend Setup

1. **Install dependencies:**
```bash
cd frontend
npm install
```

2. **Configure environment:**
```bash
# Create .env file in frontend/
VITE_API_BASE_URL=http://localhost:8000/api/v1
```

3. **Run the development server:**
```bash
npm run dev
```

Frontend will be available at `http://localhost:5173`

---

## ğŸ“¡ API Endpoints

### Ingestion

**Upload Document (PDF/TXT/MD)**
```bash
POST /api/v1/ingest/document
Content-Type: multipart/form-data

file: <file>
user_id: 1
```

**Upload Audio**
```bash
POST /api/v1/ingest/audio
Content-Type: multipart/form-data

file: <audio_file>
user_id: 1
```

**Ingest Webpage**
```bash
POST /api/v1/ingest/webpage
Content-Type: application/json

{
  "url": "https://example.com/article",
  "user_id": 1
}
```

### Query

**Ask a Question**
```bash
POST /api/v1/query
Content-Type: application/json

{
  "user_id": 1,
  "question": "What did I learn about RAG last week?",
  "source_id": 42  // Optional: focus on specific source
}
```

Response:
```json
{
  "answer": "Last week you learned about...",
  "timeline_chunks": [...],
  "document_chunks": [...],
  "dates_used": ["2025-01-10", "2025-01-11"],
  "confidence": 0.87
}
```

### Timeline

**Get Daily Timeline**
```bash
GET /api/v1/timeline/daily?user_id=1&days=30
```

**Download Day Notes (PDF)**
```bash
GET /api/v1/timeline/day-notes?user_id=1&target_date=2025-01-15
```

### Sessions

**Get Current Session**
```bash
GET /api/v1/sessions/current?user_id=1
```

**Clear Session**
```bash
POST /api/v1/sessions/clear?user_id=1
```

**Remove Source from Session**
```bash
DELETE /api/v1/sessions/source/{source_id}?user_id=1
```

---

## ğŸ¯ Usage Examples

### Example 1: Literature Review

```bash
# Upload papers
curl -X POST http://localhost:8000/api/v1/ingest/document \
  -F "file=@gpt4_paper.pdf" \
  -F "user_id=1"

curl -X POST http://localhost:8000/api/v1/ingest/document \
  -F "file=@rag_survey.pdf" \
  -F "user_id=1"

# Query across papers
curl -X POST http://localhost:8000/api/v1/query \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": 1,
    "question": "Compare the RAG architectures mentioned in these papers"
  }'
```

### Example 2: Meeting Analysis

```bash
# Upload meeting recording
curl -X POST http://localhost:8000/api/v1/ingest/audio \
  -F "file=@team_meeting.mp3" \
  -F "user_id=1"

# Ask about the meeting
curl -X POST http://localhost:8000/api/v1/query \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": 1,
    "question": "What were the action items from todays meeting?"
  }'
```

### Example 3: Temporal Query

```bash
# Ask about learning over time
curl -X POST http://localhost:8000/api/v1/query \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": 1,
    "question": "How has my understanding of transformers evolved this month?"
  }'
```

---

## ğŸš€ Deployment

### Frontend (GitHub Pages)

```bash
cd frontend
npm run build
npm run deploy
```

The app will be deployed to `https://<username>.github.io/<repo-name>/`

### Backend (Google Cloud Run)

```bash
cd backend

# Build and deploy
gcloud run deploy timelinethinker \
  --source . \
  --region europe-west1 \
  --allow-unauthenticated \
  --set-env-vars DATABASE_URL=<your-db-url>,OPENAI_API_KEY=<your-key>
```

### Database (Managed PostgreSQL)

Recommended providers with pgvector support:
- **Neon** (https://neon.tech) - Serverless Postgres
- **Supabase** (https://supabase.com) - Open-source Firebase alternative
- **Google Cloud SQL** - Managed PostgreSQL

---

## ğŸ“Š Performance

- **Query Response Time:** < 3 seconds (p95)
- **Retrieval Accuracy:** 85% (top-5 chunks contain answer)
- **Ingestion Speed:**
  - Documents: < 30 seconds per 100 pages
  - Audio: ~2x real-time (10min audio = 20min processing)
  - Webpages: < 10 seconds
- **Concurrent Users:** 10+ (scales with Cloud Run)

---

## ğŸ“ How It Works

### Ingestion Pipeline

1. **Content Extraction**
   - PDFs: PyPDF2 + pdfplumber
   - Audio: Whisper transcription
   - Web: BeautifulSoup scraping

2. **Chunking**
   - 500-token windows with 50-token overlap
   - Preserves semantic boundaries

3. **Embedding Generation**
   - OpenAI text-embedding-3-small (1536 dims)
   - Stored with HNSW index in pgvector

4. **Entity Extraction**
   - GPT-4 extracts people, places, concepts
   - Creates knowledge graph connections

5. **Timeline Assignment**
   - Events tagged with timestamps
   - Daily summaries generated

### Query Processing

1. **Planner Agent**: Analyzes intent, extracts temporal scope
2. **Timeline Retrieval**: Filters by time, runs vector search
3. **Document Retrieval**: Semantic search with entity boosting
4. **Response Generation**: Synthesizes answer with citations

### Hybrid Ranking Formula

```python
# Timeline chunks
temporal_score = 1.0 - (days_difference / max_days)
chunk_score = semantic_similarity * 0.6 + temporal_score * 0.2

# Document chunks with entity overlap
entity_boost = shared_entity_count * 0.1
final_score = semantic_similarity + entity_boost
```

---

## ğŸ”® Future Enhancements

- [ ] Multi-user authentication (OAuth2)
- [ ] Video ingestion with keyframe extraction
- [ ] Graph-based entity reasoning
- [ ] Automatic weekly recap emails
- [ ] Spaced repetition for learning
- [ ] Collaborative workspaces
- [ ] Mobile app (React Native)
- [ ] Local-first / offline mode
- [ ] Integration with Notion, Obsidian, Roam

---

## ğŸ“„ Documentation

- [**System Design Document**](SYSTEM_DESIGN.md) - Detailed architecture and implementation
- [**Video Script**](VIDEO_SCRIPT.md) - Presentation walkthrough
- [**API Documentation**](http://localhost:8000/docs) - Interactive API docs (when running locally)

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- OpenAI for GPT-4 and Whisper APIs
- pgvector team for PostgreSQL vector extension
- FastAPI and React communities

---

## ğŸ“§ Contact

**Javin Ahuja**
- GitHub: [@jav359003](https://github.com/jav359003)
- Project Link: [https://github.com/jav359003/TimelineThinker](https://github.com/jav359003/TimelineThinker)
- Live Demo: [https://jav359003.github.io/TimelineThinker/](https://jav359003.github.io/TimelineThinker/)

---

<div align="center">
  <strong>Built with â¤ï¸ for knowledge workers everywhere</strong>
  <br><br>
  If you find this project useful, please consider giving it a â­ï¸
</div>
